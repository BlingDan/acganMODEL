{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5abc7c-d203-4aeb-a714-bb7f713d6925",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "root_path = '/root/images/extend_train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e99ac25-0ade-4a9a-af17-6e19b0a2f33a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def down_image(root_dir, pixelValues):\n",
    "    '''\n",
    "    root_dir:根目录，由于直接保存到当前目录下，建议先拷贝一份再进行此操作\n",
    "    pixlValue: 像素值\n",
    "    '''\n",
    "    for subdir in os.listdir(root_dir):\n",
    "        subdir_path = os.path.join(root_dir, subdir)\n",
    "        print(subdir_path)\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            filepath = os.path.join(subdir_path, filename)\n",
    "\n",
    "            # 判断是否为文件，打开图片\n",
    "            if(os.path.isfile(filepath)):\n",
    "                with Image.open(filepath) as img:\n",
    "                    # 缩小图片并保存\n",
    "                    img = img.resize((pixelValues, pixelValues))\n",
    "                    img.save(filepath)\n",
    "    print(\"decode Over\")\n",
    "\n",
    "def add_gaussian_noise(image, noise_level):\n",
    "    width, height = image.size\n",
    "    mean = 0\n",
    "    std = noise_level * 255\n",
    "    noise = np.random.normal(mean, std, (height, width, 3)).astype(np.uint8)\n",
    "    noisy_image = np.clip(np.array(image) + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy_image)\n",
    "\n",
    "def flipHorizontallyVertically(root_dir, noise_level=0.1):\n",
    "    \n",
    "    for subdir in os.listdir(root_dir):\n",
    "        subdir_path = os.path.join(root_dir, subdir)\n",
    "        print(subdir_path)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                filepath = os.path.join(subdir_path, filename)\n",
    "                if os.path.isfile(filepath):\n",
    "                    # 打开图像\n",
    "                    img = Image.open(filepath)\n",
    "                    # 对图像进行水平，竖直，镜像，噪声\n",
    "                    img_hflip = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    img_vflip = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                    img_mirror = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    img_noise = add_gaussian_noise(img, noise_level)\n",
    "                    # 保存翻转后的图像\n",
    "                    img_hflip.save(os.path.join(subdir_path, 'hflip_' + filename))\n",
    "                    img_vflip.save(os.path.join(subdir_path, 'vflip_' + filename))    \n",
    "                    img_noise.save(os.path.join(subdir_path, 'noise_' + filename))\n",
    "                    img_mirror.save(os.path.join(subdir_path, 'mirror_' + filename))\n",
    "\n",
    "\n",
    "def SingleClassflipHorizontallyVertically(input_dir):\n",
    "    # 单个类别的水平竖直翻转扩充根数据集\n",
    "    for filename in os.listdir(input_dir):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            # 打开图像\n",
    "            img = Image.open(filepath)\n",
    "            # 对图像进行水平翻转和竖直翻转\n",
    "            flipped_image = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            flipped_image_up_down = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            \n",
    "            # 保存处理后的图像\n",
    "            flipped_image.save(os.path.join(input_dir, 'flipped_' + filename))\n",
    "            flipped_image_up_down.save(os.path.join(input_dir, 'flipped_up_down_' + filename))\n",
    "                \n",
    "\n",
    "def split_dir_into_trainAndtest(root_dir, new_dir, test_ratio=0.2):\n",
    "    '''\n",
    "    root_dir 原始文件夹\n",
    "    nerdir   新文件夹路径\n",
    "    '''\n",
    "    # 创建目标文件夹结构\n",
    "    os.makedirs(new_dir, exist_ok=True)\n",
    "    train_dir = os.path.join(new_dir, 'train')\n",
    "    test_dir = os.path.join(new_dir, 'test')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # 遍历原始文件夹\n",
    "    for class_dir in os.listdir(root_dir):\n",
    "        class_path = os.path.join(root_dir, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        # 创建训练集和测试集中的子文件夹\n",
    "        train_class_dir = os.path.join(train_dir, class_dir)\n",
    "        test_class_dir = os.path.join(test_dir, class_dir)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "        \n",
    "        # 获取类别文件夹中的图片文件列表\n",
    "        image_files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "        num_images = len(image_files)\n",
    "        \n",
    "        # 计算测试集的样本数量\n",
    "        num_test_samples = int(num_images * test_ratio)\n",
    "        \n",
    "        # 随机选择测试集样本\n",
    "        test_samples = random.sample(image_files, num_test_samples)\n",
    "        \n",
    "        # 将测试集样本移动到测试集文件夹\n",
    "        for test_sample in test_samples:\n",
    "            src_path = os.path.join(class_path, test_sample)\n",
    "            dst_path = os.path.join(test_class_dir, test_sample)\n",
    "            shutil.move(src_path, dst_path)\n",
    "        \n",
    "        # 将剩余的训练集样本移动到训练集文件夹\n",
    "        for train_sample in os.listdir(class_path):\n",
    "            src_path = os.path.join(class_path, train_sample)\n",
    "            dst_path = os.path.join(train_class_dir, train_sample)\n",
    "            shutil.move(src_path, dst_path)\n",
    "    print(\"split_dir_into_trainAndtest Over\")\n",
    "    \n",
    "    \n",
    "def makeDecodeDatasetpreToNum(original_dataset_dir, new_dataset_dir, num):\n",
    "    # 类别列表\n",
    "    class_names = os.listdir(original_dataset_dir)\n",
    "\n",
    "    # 每个类别要选取的图片数量\n",
    "    num_images_per_class = num\n",
    "\n",
    "    # 创建新文件夹\n",
    "    os.makedirs(new_dataset_dir, exist_ok=True)\n",
    "\n",
    "    # 从每个类别中随机选择指定数量的图片，并将它们复制到新文件夹中对应的子文件夹中\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(original_dataset_dir, class_name)\n",
    "        selected_images_dir = os.path.join(new_dataset_dir, class_name)\n",
    "        os.makedirs(selected_images_dir, exist_ok=True)\n",
    "    \n",
    "        # 获取该类别下的所有图片文件名\n",
    "        image_files = os.listdir(class_dir)\n",
    "    \n",
    "        # 随机选择指定数量的图片\n",
    "        selected_images = random.sample(image_files, num_images_per_class)\n",
    "\n",
    "        # 复制选中的图片到新文件夹的对应子文件夹中\n",
    "        for image in selected_images:\n",
    "            src = os.path.join(class_dir, image)\n",
    "            dst = os.path.join(selected_images_dir, image)\n",
    "            shutil.copyfile(src, dst)\n",
    "    \n",
    "    print(\"makeDecodeDatasetprtToNum Over\")\n",
    "\n",
    "def balance_file_count(root):\n",
    "    '''\n",
    "    将文件夹下的所有子文件夹的文件数目减至与最小文件夹相同\n",
    "    '''\n",
    "    # 获取root文件夹下的子文件夹列表\n",
    "    subfolders = [f for f in os.listdir(root) if os.path.isdir(os.path.join(root, f))]\n",
    "\n",
    "    # 获取最小文件数量\n",
    "    min_file_count = min([len(os.listdir(os.path.join(root, subfolder))) for subfolder in subfolders])\n",
    "\n",
    "    # 将每个子文件夹中的文件数量减至相同\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(root, subfolder)\n",
    "        files = os.listdir(subfolder_path)\n",
    "        excess_files = files[min_file_count:]\n",
    "        \n",
    "        # 删除多余的文件\n",
    "        for file in excess_files:\n",
    "            file_path = os.path.join(subfolder_path, file)\n",
    "            os.remove(file_path)\n",
    "    print(\"balance_file_count Over\")\n",
    "\n",
    "    \n",
    "def convert_image_format(root_dir, target_format=\".JPG\"):\n",
    "    '''\n",
    "    修改格式\n",
    "    '''\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            if file_path.endswith(\".jpg\") or file_path.endswith(\".jpeg\") or file_path.endswith(\".png\"):\n",
    "                image = Image.open(file_path)\n",
    "                new_file_path = os.path.splitext(file_path)[0] + target_format\n",
    "                image.save(new_file_path, \"JPEG\")\n",
    "                os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6af35c44-80de-47f6-9caa-34a171503d95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance_file_count Over\n"
     ]
    }
   ],
   "source": [
    "# convert_image_format('/root/images/wheat_leaf_512')\n",
    "# split_dir_into_trainAndtest('/root/images/wheat_leaf_512', '/root/images/splited512', test_ratio=0.3)\n",
    "# balance_file_count('/root/images/splited512/test')\n",
    "# flipHorizontallyVertically('/root/images/splited512/train')\n",
    "balance_file_count('/root/images/splited512/train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543aa320-a4ca-4ff8-85a3-ff4233fda9a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}