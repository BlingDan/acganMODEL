{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd462c3d-fa45-4384-9106-239af78f4b63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50)           150         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 150)          0           input_1[0][0]                    \n",
      "                                                                 embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32768)        4915200     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 8, 8, 512)    0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 8, 8, 512)    2048        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 8, 8, 512)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 256)  3276800     re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 256)  1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 16, 16, 256)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 128)  819200      re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 128)  512         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 32, 32, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   204800      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 3)  4800        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 3)  0           conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 9,224,790\n",
      "Trainable params: 9,222,870\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "\n",
    "physical_device = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_device[0], True)\n",
    "\n",
    "# 生成器 128* 128 * 3\n",
    "def generator_model():\n",
    "    noise = tf.keras.layers.Input(shape=((noise_dim,))) # 输入的噪声是100维\n",
    "    label = tf.keras.layers.Input(shape=(())) # 输入的标签就是1个数，但是这个数可以表示有3个类别，所以在下面Embedding第一个是3,第二个是50是映射成50个神经元\n",
    "    \n",
    "    x = tf.keras.layers.Embedding(3, 50, input_length=1)(label) # 把一个长度是1的标签(没有有one-hot编码)\n",
    "    \n",
    "    # 把x和noise合并在一起变成长度为150的向量，并希望最终得到一个(128,128,3)的图像\n",
    "    x = tf.keras.layers.concatenate([noise, x])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(8*8*64*8, use_bias=False)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Reshape((8, 8, 64*8))(x) # 注意reshape大写R # 现在形状是(8,8,64*8)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    #下面开始反卷积: (8, 8, 64*8) -> (16, 16, 64*4) -> (32, 32, 64*2) -> (64, 64, 64) -> (128, 128, 3)\n",
    "    #(8, 8, 64*8) -> (16, 16, 64*4)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64*4, (5,5), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    #(16, 16, 64*4) -> (32, 32, 64*2)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64*2, (5,5), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # (32, 32, 64*2) -> (64, 64, 64)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)  \n",
    "    \n",
    "    #(64, 64, 64) -> (128, 128, 3)\n",
    "    x = tf.keras.layers.Conv2DTranspose(3, (5,5), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[noise, label], outputs=x)\n",
    "    return model\n",
    "\n",
    "# generator = generator_model()\n",
    "# generator = tf.keras.model()\n",
    "generator_path = 'Final128generator_model.h5'\n",
    "# generator.load_weights(generator_path)\n",
    "generator = tf.keras.models.load_model(generator_path)\n",
    "\n",
    "generator.summary()\n",
    "\n",
    "nsample = 10\n",
    "noise_dim = 100\n",
    "class_names = ['Crown_and_Root_Rot', 'healthy', 'stripe_rust']\n",
    "image_counts = {'Crown_and_Root_Rot': 1200, 'healthy': 1000, 'stripe_rust': 800}\n",
    "output_root = '/root/images/balanceGenImage'\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "index_to_name = {i: class_name for i, class_name in enumerate(class_names)}\n",
    "\n",
    "def plot_gen_image(model, noise, label):\n",
    "    gen_image = model((noise, label), training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 3))\n",
    "    for i in range(10):\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow((gen_image[i,:,:] + 1)/2)\n",
    "        plt.title(condition[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "753d8ee1-87b5-4ae0-bb91-957192c5862f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始生成 Crown_and_Root_Rot\n",
      "开始生成 healthy\n",
      "开始生成 stripe_rust\n"
     ]
    }
   ],
   "source": [
    "# Generate and save images for each class\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(\"开始生成\", class_name)\n",
    "    images_per_class = image_counts[class_name]\n",
    "    \n",
    "    # 扩大噪声的变化范围\n",
    "    noise_seed = tf.random.normal([images_per_class, noise_dim], mean=0.0, stddev=1.0)\n",
    "    noise_seed = noise_seed * 2.0  # 增加噪声范围\n",
    "    \n",
    "    label_seed = np.full((images_per_class, 1), i)\n",
    "    condition = [index_to_name.get(i) for i in label_seed.T[0]]\n",
    "    \n",
    "    gen_image = generator.predict([noise_seed, label_seed])  # Generate images\n",
    "    \n",
    "    # Create class folder if it doesn't exist\n",
    "    class_folder = os.path.join(output_root, class_name)\n",
    "    os.makedirs(class_folder, exist_ok=True)\n",
    "    \n",
    "    # Save generated images\n",
    "    for j in range(images_per_class):\n",
    "        image = (gen_image[j,:,:] + 1) / 2\n",
    "        image_path = os.path.join(class_folder, f\"Gen_image_{j}.JPG\")\n",
    "        plt.imsave(image_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67dda7-bbfa-448c-b6ee-c5dd38256008",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71ce09-a655-44a5-b2dd-6a8f163c2317",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb3989-7750-4b47-a8c9-fc98f5f531d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}